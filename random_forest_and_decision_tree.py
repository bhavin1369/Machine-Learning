# -*- coding: utf-8 -*-
"""Random Forest and Decision Tree

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11Xj5OrLSXj71-oULtsf3IDW-I0HpecEl
"""

import pandas as pd
import numpy as np
from sklearn.datasets import fetch_openml
from sklearn.preprocessing import LabelEncoder,OneHotEncoder

#load the dataset
data=fetch_openml('titanic',version=1,as_frame=True)
print(data)

data['feature_names']

#drop the empty values
data_f=data.frame.copy()

data=data_f[['age','sex','fare','embarked','pclass','survived']].dropna()

set(list(data['embarked']))

#label encoding
le=LabelEncoder()
data['embarked_le']=le.fit_transform(data['embarked'])

data.columns

data['embarked_le']

#One-Hot Encoder
ohe=OneHotEncoder()
df_ohe=pd.get_dummies(data['sex'])
df_ohe=pd.get_dummies(data,columns=['sex'])
df_ohe

#load the dataset of disables
from sklearn.datasets import load_diabetes

data=load_diabetes(as_frame=True)
data=data.frame
print(data)

data.describe()

print(data.columns)

import seaborn as sns
import matplotlib.pyplot as plt

#set corerelation in-between the features
corr=data.corr()
plt.figure(figsize=(10,10))
sns.heatmap(corr,annot=True)
plt.show()

#features importance
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

data.columns

x_train,x_test,y_train,y_test=train_test_split(data.drop('target',axis=1),data['target'],test_size=0.2,random_state=42)

from sklearn.tree import DecisionTreeRegressor
tree=DecisionTreeRegressor(max_depth=3)
tree=tree.fit(x_train,y_train)

importance=pd.Series(tree.feature_importances_,index=x_train.columns)
importance

