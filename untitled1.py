# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TEVBHHrJd-wsx_kdYIi2RkHe__91eXe1
"""

import numpy as np
import pandas as pd

#load the dataset
data=pd.read_csv("/content/titanic.csv")
data.head()

data.shape

data.describe()

data.info()

data.isnull().sum()

data=pd.read_csv("/content/titanic.csv")
data=data.drop(columns=['Name','Ticket'])
data.shape

data.columns

data.isnull().sum()/data.shape[0]*100

data=data.drop(columns=['Cabin'])
data.shape

data.dropna(subset=['Embarked'],axis=0,inplace=True)
data.shape

data=data.fillna(data.Age.mean())

data.isnull().sum()



"""text analysis over stack overflow"""

!pip install kaggle

import os
os.environ['KAGGLE_CONFIG_DIR']="/content"

!kaggle datasets download stackoverflow/stack-overflow-2018-developer-survey

!unzip stack-overflow-2018-developer-survey.zip

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#load the dataset
schema=pd.read_csv("/content/survey_results_schema.csv")
schema.head()

data=pd.read_csv("/content/survey_results_public.csv")
data.head()

data.shape

#count te number of null values in each feature
data=pd.read_csv("/content/survey_results_public.csv")
data.isnull().sum()
#percentage of null values
data.isnull().sum()/data.shape[0]*100

#determine the num of people contributing to open source projects
# Show the distribution of responses
print("Open Source Contribution Frequency:\n")
print(data['OpenSource'].value_counts())

#draw the piechart for the num of people who finds coding as hobby
hobby_counts = data['Hobby'].value_counts()
plt.figure(figsize=(6, 6))
hobby_counts.plot.pie(autopct='%1.1f%%', startangle=90, colors=['#4CAF50', '#FFC107'])
plt.title(' Do You Code as a Hobby?')
plt.ylabel('')
plt.show()

#determine the top 20 countrys from where the respones are obtain
top_countries = data['Country'].value_counts().head(20)
print("\nTop 20 Countries by Responses:\n")
print(top_countries)

#do other 5 analysis as per your own thinking diffrent charts and graphs
#Employment Status Pie Chart

plt.figure(figsize=(8, 5))
data['Employment'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90)
plt.title('Employment Status of Respondents')
plt.ylabel('')
plt.show()

#Age Distribution
plt.figure(figsize=(10, 5))
sns.histplot(data['Age'].dropna(), bins=30, kde=True, color='green')
plt.title('Age Distribution of Respondents')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.show()

#Salary Distribution
for col in ['ConvertedCompYearly', 'CompTotal']:
    if col in data.columns:
        plt.figure(figsize=(10, 5))
        sns.boxplot(x=data[col].dropna(), color='purple')
        plt.title(f'{col} Distribution')
        plt.xlabel('Salary (USD)')
        plt.show()
        break

#List all column names
print(data.columns.tolist())

# Count how many people are from India and visualize it
india_count = data[data['Country'] == 'India'].shape[0]
plt.figure(figsize=(4, 6))
plt.bar(['India'], [india_count], color='teal')
plt.title('Number of Respondents from India')
plt.ylabel('Number of People')
plt.show()

#See how many unique countries are in the data
unique_countries = data['Country'].nunique()
print("Number of unique countries:", unique_countries)

#Find average age of respondents
if 'Age' in data.columns:
    # Convert 'Age' column to numeric, coercing errors to NaN
    data['Age'] = pd.to_numeric(data['Age'], errors='coerce')
    avg_age = data['Age'].mean()
    print("Average age:", round(avg_age, 2))

#Bar plot of top 5 countries
top5 = data['Country'].value_counts().head(5)
top5.plot(kind='bar', color='teal')
plt.title('Top 5 Countries by Responses')
plt.ylabel('Number of People')
plt.show()

# Pie chart of gender distribution
gender_counts = data['Gender'].value_counts().head(4)  # Avoid long labels
gender_counts.plot.pie(autopct='%1.1f%%', startangle=90)
plt.title('Gender Distribution')
plt.ylabel('')
plt.show()

